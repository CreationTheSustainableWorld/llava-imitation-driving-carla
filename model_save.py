import os
import torch
import torch.nn as nn
from transformers import AutoProcessor, LlavaForConditionalGeneration

# === å…±é€šè¨­å®š ===
model_id = "llava-hf/llava-1.5-7b-hf"
save_dir_base = "./saved_llava_models"
os.makedirs(save_dir_base, exist_ok=True)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === original ãƒ¢ãƒ‡ãƒ«ä¿å­˜æ¸ˆã¿ã®ãŸã‚çœç•¥ ===

# === delete ãƒ¢ãƒ‡ãƒ«ï¼ˆä¸­é–“ç‰¹å¾´æŠ½å‡ºã¾ã§ï¼‰ ===
model_delete = LlavaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.float16).to(device)
save_path_delete = os.path.join(save_dir_base, "llava-1.5-7b-hf_delete")
model_delete.save_pretrained(save_path_delete)
print(f"âœ… Saved delete model to {save_path_delete}")

# === addition ãƒ¢ãƒ‡ãƒ«ï¼ˆä¸­é–“ç‰¹å¾´â†’è¡Œå‹•å‡ºåŠ›ï¼‰ ===
class LlavaWithActionHead(nn.Module):
    def __init__(self, base_model):
        super().__init__()
        self.base = base_model

        # ğŸ”§ LLaVAã®ä¸­ã®LLaMAã®hidden sizeã‚’å–å¾—
        hidden_size = self.base.language_model.config.hidden_size
        hidden_size = self.base.language_model.config.hidden_size


        self.action_head = nn.Sequential(
            nn.Linear(hidden_size, 512),
            nn.ReLU(),
            nn.Linear(512, 3)  # å‡ºåŠ›: steer, throttle, brake
        )

    def forward(self, input_ids, attention_mask=None, pixel_values=None):
        outputs = self.base(
            input_ids=input_ids,
            attention_mask=attention_mask,
            pixel_values=pixel_values,
            output_hidden_states=True,
            return_dict=True
        )

        # ğŸ”½ decoderã®æœ€çµ‚å±¤ã®[CLS]ãƒˆãƒ¼ã‚¯ãƒ³ã‚’åˆ©ç”¨
        hidden_state = outputs.hidden_states[-1][:, 0]  # shape: (B, hidden)

        return self.action_head(hidden_state)

model_base = LlavaForConditionalGeneration.from_pretrained(model_id, torch_dtype=torch.float16).to(device)
model_add = LlavaWithActionHead(model_base).to(device)

save_path_add = os.path.join(save_dir_base, "llava-1.5-7b-hf_addition")
os.makedirs(save_path_add, exist_ok=True)
torch.save(model_add.state_dict(), os.path.join(save_path_add, "pytorch_model.bin"))
print(f"âœ… Saved addition model to {save_path_add}")
